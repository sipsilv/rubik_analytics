{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c9ef574",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 17\u001b[0m\n\u001b[0;32m      2\u001b[0m required_columns \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexchange\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexchange_token\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlot_size\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     14\u001b[0m ]\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Keep only existing columns\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m existing_columns \u001b[38;5;241m=\u001b[39m [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m required_columns \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns]\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Filter dataframe\u001b[39;00m\n\u001b[0;32m     20\u001b[0m final_df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mloc[:, existing_columns]\u001b[38;5;241m.\u001b[39mcopy()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Required columns (DB schema)\n",
    "required_columns = [\n",
    "    \"exchange\",\n",
    "    \"exchange_token\",\n",
    "    \"trading_symbol\",\n",
    "    \"name\",\n",
    "    \"instrument_type\",\n",
    "    \"segment\",\n",
    "    \"series\",\n",
    "    \"isin\",\n",
    "    \"expiry_date\",\n",
    "    \"strike_price\",\n",
    "    \"lot_size\"\n",
    "]\n",
    "\n",
    "# Keep only existing columns\n",
    "existing_columns = [c for c in required_columns if c in df.columns]\n",
    "\n",
    "# Filter dataframe\n",
    "final_df = df.loc[:, existing_columns].copy()\n",
    "final_df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e508655a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29998858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables: [('schedulers',), ('series_lookup',), ('series_lookup_metadata',), ('symbols',), ('transformation_scripts',), ('upload_logs',)]\n",
      "Row count: 172734\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "\n",
    "# DB PATH\n",
    "db_path = r\"C:\\Users\\jallu\\OneDrive\\pgp\\Python\\Stock predictor\\rubik-analytics\\data\\symbols\\symbols.duckdb\"\n",
    "\n",
    "# CONNECT\n",
    "con = duckdb.connect(db_path)\n",
    "\n",
    "# CHECK TABLES\n",
    "tables = con.execute(\"SHOW TABLES\").fetchall()\n",
    "print(\"Tables:\", tables)\n",
    "\n",
    "# ROW COUNT (change table name if needed)\n",
    "row_count = con.execute(\"SELECT COUNT(*) FROM symbols\").fetchone()[0]\n",
    "print(\"Row count:\", row_count)\n",
    "\n",
    "# CLOSE\n",
    "con.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed224a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column headers:\n",
      "id\n",
      "exchange\n",
      "trading_symbol\n",
      "exchange_token\n",
      "name\n",
      "instrument_type\n",
      "segment\n",
      "series\n",
      "isin\n",
      "expiry_date\n",
      "strike_price\n",
      "lot_size\n",
      "status\n",
      "source\n",
      "created_at\n",
      "updated_at\n",
      "last_updated_at\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "\n",
    "# DB PATH\n",
    "db_path = r\"C:\\Users\\jallu\\OneDrive\\pgp\\Python\\Stock predictor\\rubik-analytics\\data\\symbols\\symbols.duckdb\"\n",
    "\n",
    "# CONNECT\n",
    "con = duckdb.connect(db_path)\n",
    "\n",
    "# GET COLUMN HEADERS\n",
    "columns = con.execute(\"DESCRIBE symbols\").fetchall()\n",
    "\n",
    "print(\"Column headers:\")\n",
    "for col in columns:\n",
    "    print(col[0])\n",
    "\n",
    "# CLOSE\n",
    "con.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dbd030b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionException",
     "evalue": "Connection Error: Connection already closed!",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mConnectionException\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m table \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33msymbol_upload_logs\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msymbols\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     count = \u001b[43mcon\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSELECT COUNT(*) FROM \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtable\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m.fetchone()[\u001b[32m0\u001b[39m]\n\u001b[32m      3\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcount\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mConnectionException\u001b[39m: Connection Error: Connection already closed!"
     ]
    }
   ],
   "source": [
    "for table in [\"symbol_upload_logs\", \"symbols\"]:\n",
    "    count = con.execute(f\"SELECT COUNT(*) FROM {table}\").fetchone()[0]\n",
    "    print(f\"{table}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8480e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import duckdb\n",
    "import sqlite3\n",
    "\n",
    "# Path to connections data\n",
    "base_path = Path(r\"C:\\Users\\jallu\\OneDrive\\pgp\\Python\\Stock predictor\\rubik-analytics\")\n",
    "connections_file = base_path / \"data\" / \"connections\" / \"connections.json\"\n",
    "active_file = base_path / \"data\" / \"connections\" / \"active_connection.json\"\n",
    "\n",
    "# Load connections\n",
    "connections_data = {}\n",
    "active_connections = {}\n",
    "\n",
    "if connections_file.exists():\n",
    "    with open(connections_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        connections_data = {conn[\"id\"]: conn for conn in data.get(\"connections\", [])}\n",
    "\n",
    "if active_file.exists():\n",
    "    with open(active_file, 'r') as f:\n",
    "        active_connections = json.load(f)\n",
    "\n",
    "# Test connection status\n",
    "def test_connection(conn_type, config):\n",
    "    \"\"\"Test if a database connection is working\"\"\"\n",
    "    try:\n",
    "        if conn_type == \"sqlite\" or conn_type == \"sqlite3\":\n",
    "            path = config.get(\"path\") or config.get(\"database\")\n",
    "            if path and os.path.exists(path):\n",
    "                conn = sqlite3.connect(path)\n",
    "                conn.execute(\"SELECT 1\")\n",
    "                conn.close()\n",
    "                return \"✓ Connected\"\n",
    "            return \"✗ File not found\"\n",
    "        elif conn_type in [\"duckdb\", \"duckdb_direct\", \"duckdb_sqlalchemy\"]:\n",
    "            path = config.get(\"path\")\n",
    "            if path:\n",
    "                if os.path.exists(path):\n",
    "                    con = duckdb.connect(path)\n",
    "                    con.execute(\"SELECT 1\")\n",
    "                    con.close()\n",
    "                    return \"✓ Connected\"\n",
    "                return \"✗ File not found\"\n",
    "            # Multi-database case\n",
    "            return \"✓ Configured\"\n",
    "        else:\n",
    "            return \"? Unknown type\"\n",
    "    except Exception as e:\n",
    "        return f\"✗ Error: {str(e)[:30]}\"\n",
    "\n",
    "# Display connections\n",
    "print(\"=\" * 100)\n",
    "print(\"DATABASE CONNECTIONS STATUS\")\n",
    "print(\"=\" * 100)\n",
    "print()\n",
    "\n",
    "if connections_data:\n",
    "    # Create a list for display\n",
    "    conn_list = []\n",
    "    for conn_id, conn in connections_data.items():\n",
    "        category = conn.get(\"category\", \"N/A\")\n",
    "        is_active = conn_id in active_connections.values()\n",
    "        active_marker = \"✓ ACTIVE\" if is_active else \"  \"\n",
    "        \n",
    "        conn_type = conn.get(\"type\", \"N/A\")\n",
    "        name = conn.get(\"name\", \"N/A\")\n",
    "        \n",
    "        # Get database path(s)\n",
    "        config = conn.get(\"config\", {})\n",
    "        if \"path\" in config:\n",
    "            db_path = config[\"path\"]\n",
    "            # Test connection\n",
    "            conn_status = test_connection(conn_type, config)\n",
    "        elif conn_type == \"duckdb\" and any(k in config for k in [\"ohlcv\", \"indicators\", \"signals\", \"jobs\"]):\n",
    "            db_path = f\"Multiple: {', '.join([k for k in config.keys() if k != 'path'])}\"\n",
    "            conn_status = \"✓ Configured (multi-DB)\"\n",
    "        else:\n",
    "            db_path = \"N/A\"\n",
    "            conn_status = \"? Not configured\"\n",
    "        \n",
    "        conn_list.append({\n",
    "            \"Active\": active_marker,\n",
    "            \"Name\": name,\n",
    "            \"Type\": conn_type,\n",
    "            \"Category\": category,\n",
    "            \"Connection Status\": conn_status,\n",
    "            \"Database Path\": str(db_path)[:60] + \"...\" if len(str(db_path)) > 60 else str(db_path)\n",
    "        })\n",
    "    \n",
    "    # Display as DataFrame\n",
    "    df_connections = pd.DataFrame(conn_list)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "    pd.set_option('display.max_colwidth', 70)\n",
    "    print(df_connections.to_string(index=False))\n",
    "    print()\n",
    "    \n",
    "    # Show active connections summary\n",
    "    print(\"-\" * 100)\n",
    "    print(\"ACTIVE CONNECTIONS BY CATEGORY:\")\n",
    "    print(\"-\" * 100)\n",
    "    for category, conn_id in sorted(active_connections.items()):\n",
    "        if conn_id:\n",
    "            conn = connections_data.get(conn_id, {})\n",
    "            config = conn.get(\"config\", {})\n",
    "            conn_type = conn.get(\"type\", \"N/A\")\n",
    "            status = test_connection(conn_type, config)\n",
    "            print(f\"  {category:20s} → {conn.get('name', conn_id):40s} ({conn_type:15s}) {status}\")\n",
    "        else:\n",
    "            print(f\"  {category:20s} → None\")\n",
    "    print()\n",
    "    \n",
    "    # Summary\n",
    "    active_count = sum(1 for cid in connections_data.keys() if cid in active_connections.values())\n",
    "    total_count = len(connections_data)\n",
    "    print(f\"Summary: {active_count} active out of {total_count} total connections\")\n",
    "else:\n",
    "    print(\"No connections found.\")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "970b01ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jallu\\AppData\\Local\\Temp\\ipykernel_70964\\2181961351.py:3: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price             Close        High          Low         Open      Volume\n",
      "Ticker      RELIANCE.NS RELIANCE.NS  RELIANCE.NS  RELIANCE.NS RELIANCE.NS\n",
      "Date                                                                     \n",
      "2025-12-10  1536.900024      1547.5  1531.400024  1534.000000     7991629\n",
      "2025-12-11  1545.000000      1550.0  1524.000000  1536.900024     4706197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "df = yf.download(\n",
    "    \"RELIANCE.NS\",\n",
    "    start=\"2025-12-10\",\n",
    "    end=\"2025-12-12\",\n",
    "    interval=\"1d\"\n",
    ")\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f88cf0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables: [('users',), ('access_requests',), ('feedback',), ('sessions',), ('feature_requests',), ('audit_logs',), ('sqlite_sequence',), ('symbols',), ('transformation_scripts',), ('symbol_upload_logs',), ('scheduled_ingestions',), ('ingestion_sources',), ('connections',)]\n",
      "Row count: 3\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "# DB PATH\n",
    "db_path = r\"C:\\Users\\jallu\\OneDrive\\pgp\\Python\\Stock predictor\\rubik-analytics\\backend\\data\\auth\\sqlite\\auth.db\"\n",
    "\n",
    "# CONNECT\n",
    "con = sqlite3.connect(db_path)\n",
    "cur = con.cursor()\n",
    "\n",
    "# CHECK TABLES\n",
    "cur.execute(\"\"\"\n",
    "    SELECT name \n",
    "    FROM sqlite_master \n",
    "    WHERE type='table';\n",
    "\"\"\")\n",
    "tables = cur.fetchall()\n",
    "print(\"Tables:\", tables)\n",
    "\n",
    "# ROW COUNT (change table name if needed)\n",
    "table_name = \"users\"  # <-- replace with actual table name\n",
    "cur.execute(f\"SELECT COUNT(*) FROM {table_name}\")\n",
    "row_count = cur.fetchone()[0]\n",
    "print(\"Row count:\", row_count)\n",
    "\n",
    "# CLOSE\n",
    "con.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f39943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                username                   email        mobile  \\\n",
      "0   2  testuser@rubikview.com  testuser@rubikview.com    9515625875   \n",
      "1   4                 sandeep       sandeep@rubik.com    8686504620   \n",
      "2   5                   admin     admin@rubikview.com  +10000000000   \n",
      "\n",
      "                                     hashed_password         role  is_active  \\\n",
      "0  $2b$12$u7Sm8k/Rw6dstyT0P4lTnu9.gNJmE6lsZb08Ql9...        admin          1   \n",
      "1  $2b$12$FXa/jswKk5f1fmGg/hYNC.YAMz/Y8kdMpIzEoaa...  super_admin          1   \n",
      "2  $2b$12$CoWtm2TUU.8RhkxWsFhct.ISQbNrVflwPRhprmB...  super_admin          1   \n",
      "\n",
      "            created_at                  updated_at  \\\n",
      "0  2025-12-19 16:29:34  2025-12-23 19:47:00.676215   \n",
      "1  2025-12-20 12:24:46         2025-12-26 06:23:39   \n",
      "2  2025-12-21 06:56:55         2025-12-22 06:07:32   \n",
      "\n",
      "                    last_seen theme_preference           name  \\\n",
      "0  2025-12-20 08:28:11.304847             dark         testin   \n",
      "1  2025-12-26 06:15:38.376916             dark  Sandeep jallu   \n",
      "2  2025-12-22 06:07:32.443174             dark           None   \n",
      "\n",
      "                                user_id              last_active_at  \\\n",
      "0  faf3fc4a-23e2-4b55-80cb-0a38fc45acd0                        None   \n",
      "1                            7285504620  2025-12-26 06:23:39.635896   \n",
      "2  5395507f-77d7-451b-9d1e-8dab1b0a5057  2025-12-22 06:07:32.443202   \n",
      "\n",
      "  account_status  \n",
      "0         ACTIVE  \n",
      "1         ACTIVE  \n",
      "2         ACTIVE  \n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# DB PATH\n",
    "db_path = r\"C:\\Users\\jallu\\OneDrive\\pgp\\Python\\Stock predictor\\rubik-analytics\\backend\\data\\auth\\sqlite\\auth.db\"\n",
    "\n",
    "def fetch_table_safe_df(table_name, limit=5):\n",
    "    con = sqlite3.connect(db_path)\n",
    "    cur = con.cursor()\n",
    "\n",
    "    # VALIDATE TABLE NAME\n",
    "    cur.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\n",
    "    allowed = [t[0] for t in cur.fetchall()]\n",
    "\n",
    "    if table_name not in allowed:\n",
    "        con.close()\n",
    "        raise ValueError(\"Invalid table name\")\n",
    "\n",
    "    # FETCH FIRST N ROWS\n",
    "    query = f\"\"\"\n",
    "        SELECT *\n",
    "        FROM {table_name}\n",
    "        ORDER BY rowid ASC\n",
    "        LIMIT {limit}\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_sql_query(query, con)\n",
    "\n",
    "    con.close()\n",
    "    return df\n",
    "\n",
    "\n",
    "# =========================\n",
    "# USAGE\n",
    "# =========================\n",
    "df = fetch_table_safe_df(\"users\", limit=5)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffebadeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: requests in c:\\users\\jallu\\appdata\\roaming\\python\\python313\\site-packages (2.32.4)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\jallu\\appdata\\roaming\\python\\python313\\site-packages (4.13.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\jallu\\appdata\\roaming\\python\\python313\\site-packages (2.3.0)\n",
      "Requirement already satisfied: lxml in c:\\users\\jallu\\appdata\\roaming\\python\\python313\\site-packages (5.4.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\jallu\\appdata\\roaming\\python\\python313\\site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jallu\\appdata\\roaming\\python\\python313\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jallu\\appdata\\roaming\\python\\python313\\site-packages (from requests) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jallu\\appdata\\roaming\\python\\python313\\site-packages (from requests) (2025.6.15)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\jallu\\appdata\\roaming\\python\\python313\\site-packages (from beautifulsoup4) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\jallu\\appdata\\roaming\\python\\python313\\site-packages (from beautifulsoup4) (4.15.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\jallu\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jallu\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jallu\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\jallu\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jallu\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install requests beautifulsoup4 pandas lxml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abb57ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page title: Reliance Industries Ltd share price | About Reliance Industr | Key Insights - Screener\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.screener.in/company/RELIANCE/\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers, timeout=15)\n",
    "response.raise_for_status()\n",
    "\n",
    "soup = BeautifulSoup(response.text, \"lxml\")\n",
    "\n",
    "print(\"Page title:\", soup.title.text.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993d13ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'if' statement on line 93 (3177863400.py, line 95)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 95\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mif bs_df is not None:\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m expected an indented block after 'if' statement on line 93\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "SYMBOL = \"AAA Technologies\"\n",
    "URL = f\"https://www.screener.in/company/{SYMBOL}/consolidated/\"\n",
    "\n",
    "HEADERS = {\n",
    "    \"User-Agent\": (\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/131.0 Safari/537.36\"\n",
    "    ),\n",
    "    \"Referer\": \"https://www.screener.in/\"\n",
    "}\n",
    "\n",
    "def fetch_soup(url: str) -> BeautifulSoup:\n",
    "    resp = requests.get(url, headers=HEADERS, timeout=20)\n",
    "    resp.raise_for_status()\n",
    "    return BeautifulSoup(resp.text, \"html.parser\")\n",
    "\n",
    "def parse_header_fundamentals(soup: BeautifulSoup) -> dict:\n",
    "    \"\"\"\n",
    "    Extract Market Cap, Price, PE, ROE, etc. from the top info block.\n",
    "    This uses regex on full text to be more robust to minor HTML changes.\n",
    "    \"\"\"\n",
    "    txt = soup.get_text(\"\\n\")\n",
    "\n",
    "    def grab(pattern):\n",
    "        m = re.search(pattern, txt)\n",
    "        return m.group(1).strip() if m else None\n",
    "\n",
    "    data = {}\n",
    "    data[\"Market Cap (Cr)\"] = grab(r\"Market Cap\\s*₹\\s*([0-9,\\.]+)\\s*Cr\")\n",
    "    data[\"Current Price\"] = grab(r\"Current Price\\s*₹\\s*([0-9,\\.]+)\")\n",
    "    data[\"High / Low\"] = grab(r\"High\\s*/\\s*Low\\s*₹\\s*([0-9,\\. /]+)\")\n",
    "    data[\"Stock P/E\"] = grab(r\"Stock P/E\\s*([0-9\\.]+)\")\n",
    "    data[\"Book Value\"] = grab(r\"Book Value\\s*₹\\s*([0-9,\\.]+)\")\n",
    "    data[\"Dividend Yield %\"] = grab(r\"Dividend Yield\\s*([0-9\\.]+)\\s*%\")\n",
    "    data[\"ROCE %\"] = grab(r\"ROCE\\s*([0-9\\.]+)\\s*%\")\n",
    "    data[\"ROE %\"] = grab(r\"ROE\\s*([0-9\\.]+)\\s*%\")\n",
    "    data[\"Face Value\"] = grab(r\"Face Value\\s*₹\\s*([0-9,\\.]+)\")\n",
    "    return data\n",
    "\n",
    "def parse_peer_table(soup: BeautifulSoup) -> pd.DataFrame | None:\n",
    "    \"\"\"\n",
    "    Find the peer comparison table by looking for columns like 'CMP Rs.' and 'P/E'.\n",
    "    \"\"\"\n",
    "    tables = pd.read_html(str(soup))\n",
    "    for df in tables:\n",
    "        cols = [str(c) for c in df.columns]\n",
    "        joined = \" \".join(cols)\n",
    "        if \"CMP Rs.\" in joined and \"P/E\" in joined:\n",
    "            return df\n",
    "    return None\n",
    "\n",
    "def parse_section_table(soup: BeautifulSoup, heading_text: str) -> pd.DataFrame | None:\n",
    "    \"\"\"\n",
    "    For blocks like 'Profit & Loss', 'Balance Sheet', 'Cash Flows', 'Ratios'.\n",
    "    \"\"\"\n",
    "    h = soup.find(lambda tag: tag.name in [\"h2\", \"h3\"] and heading_text in tag.get_text())\n",
    "    if not h:\n",
    "        return None\n",
    "    table = h.find_next(\"table\")\n",
    "    if not table:\n",
    "        return None\n",
    "    return pd.read_html(str(table))[0]\n",
    "\n",
    "def main():\n",
    "    soup = fetch_soup(URL)\n",
    "\n",
    "    # 1) Header fundamentals\n",
    "    header_data = parse_header_fundamentals(soup)\n",
    "    header_df = pd.DataFrame([header_data])\n",
    "    header_df.to_csv(f\"{SYMBOL}_header_fundamentals.csv\", index=False)\n",
    "    print(\"Header fundamentals:\")\n",
    "    print(header_df.T)\n",
    "\n",
    "    # 2) Peer comparison\n",
    "    peer_df = parse_peer_table(soup)\n",
    "    if peer_df is not None:\n",
    "        peer_df.to_csv(f\"{SYMBOL}_peers.csv\", index=False)\n",
    "        print(\"\\nPeer comparison (top 5):\")\n",
    "        print(peer_df.head())\n",
    "\n",
    "    # 3) Financial statements\n",
    "    pl_df = parse_section_table(soup, \"Profit & Loss\")\n",
    "    bs_df = parse_section_table(soup, \"Balance Sheet\")\n",
    "    cf_df = parse_section_table(soup, \"Cash Flows\")\n",
    "    ratio_df = parse_section_table(soup, \"Ratios\")\n",
    "\n",
    "    if pl_df is not None:\n",
    "        pl_df.to_csv(f\"{SYMBOL}_profit_loss.csv\", index=False)\n",
    "    if bs_df is not None:\n",
    "        bs_df.to_csv(f\"{SYMBOL}_balance_sheet.csv\", index=False)\n",
    "    if cf_df is not None:\n",
    "        cf_df.to_csv(f\"{SYMBOL}_cash_flows.csv\", index=False)\n",
    "    if ratio_df is not None:\n",
    "        ratio_df.to_csv(f\"{SYMBOL}_ratios.csv\", index=False)\n",
    "\n",
    "    print(\"\\nSaved CSVs for:\", SYMBOL)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66269be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page title: Reliance Industries Ltd share price | About Reliance Industr | Key Insights - Screener\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.screener.in/company/RELIANCE/\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0\",\n",
    "    \"Referer\": \"https://www.screener.in/\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers, timeout=15)\n",
    "response.raise_for_status()\n",
    "\n",
    "soup = BeautifulSoup(response.text, \"lxml\")\n",
    "\n",
    "print(\"Page title:\", soup.title.get_text(strip=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b22856b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tables found: 11\n",
      "\n",
      "==============================\n",
      "TABLE INDEX: 0\n",
      "HEADING: Quarterly Results\n",
      "SHAPE: (12, 14)\n",
      "         Unnamed: 0 Sep 2022 Dec 2022 Mar 2023 Jun 2023 Sep 2023 Dec 2023  \\\n",
      "0           Sales +   137346   125849   129674   122627   137380   127695   \n",
      "1        Expenses +   125561   110950   110542   105134   118189   110137   \n",
      "2  Operating Profit    11785    14899    19132    17493    19191    17558   \n",
      "3             OPM %       9%      12%      15%      14%      14%      14%   \n",
      "4    Other Income +     3499     2689     2750     2728     2934     2969   \n",
      "\n",
      "  Mar 2024 Jun 2024 Sep 2024 Dec 2024 Mar 2025 Jun 2025 Sep 2025  \n",
      "0   146832   129898   130108   124381   132962   116341   126335  \n",
      "1   126809   115583   116683   109168   117846   103171   111946  \n",
      "2    20023    14315    13425    15213    15116    13170    14389  \n",
      "3      14%      11%      10%      12%      11%      11%      11%  \n",
      "4     3497     3502     3801     3214     5577    13460     3445  \n",
      "\n",
      "==============================\n",
      "TABLE INDEX: 1\n",
      "HEADING: Profit & Loss\n",
      "SHAPE: (12, 14)\n",
      "         Unnamed: 0 Mar 2014 Mar 2015 Mar 2016 Mar 2017 Mar 2018 Mar 2019  \\\n",
      "0           Sales +   389178   328013   231743   240597   289188   370744   \n",
      "1        Expenses +   358244   296377   192359   197272   237430   311853   \n",
      "2  Operating Profit    30934    31636    39384    43325    51758    58891   \n",
      "3             OPM %       8%      10%      17%      18%      18%      16%   \n",
      "4    Other Income +     8879     8687     7784     8640     8203     8785   \n",
      "\n",
      "  Mar 2020 Mar 2021 Mar 2022 Mar 2023 Mar 2024 Mar 2025     TTM  \n",
      "0   336097   245050   422413   537909   531908   515425  500019  \n",
      "1   283073   211542   370007   471050   457488   457292  442131  \n",
      "2    53024    33508    52406    66859    74420    58133   57888  \n",
      "3      16%      14%      12%      12%      14%      11%     12%  \n",
      "4     9125    19114    13779    12247    11973    16030   25696  \n",
      "\n",
      "==============================\n",
      "TABLE INDEX: 2\n",
      "HEADING: Profit & Loss\n",
      "SHAPE: (4, 2)\n",
      "  Compounded Sales Growth Compounded Sales Growth.1\n",
      "0               10 Years:                        5%\n",
      "1                5 Years:                        9%\n",
      "2                3 Years:                        7%\n",
      "3                    TTM:                       -6%\n",
      "\n",
      "==============================\n",
      "TABLE INDEX: 3\n",
      "HEADING: Profit & Loss\n",
      "SHAPE: (4, 2)\n",
      "  Compounded Profit Growth Compounded Profit Growth.1\n",
      "0                10 Years:                         5%\n",
      "1                 5 Years:                         0%\n",
      "2                 3 Years:                        -4%\n",
      "3                     TTM:                         7%\n",
      "\n",
      "==============================\n",
      "TABLE INDEX: 4\n",
      "HEADING: Profit & Loss\n",
      "SHAPE: (4, 2)\n",
      "  Stock Price CAGR Stock Price CAGR.1\n",
      "0        10 Years:                21%\n",
      "1         5 Years:                12%\n",
      "2         3 Years:                10%\n",
      "3          1 Year:                27%\n",
      "\n",
      "==============================\n",
      "TABLE INDEX: 5\n",
      "HEADING: Profit & Loss\n",
      "SHAPE: (4, 2)\n",
      "  Return on Equity Return on Equity.1\n",
      "0        10 Years:                 9%\n",
      "1         5 Years:                 8%\n",
      "2         3 Years:                 8%\n",
      "3       Last Year:                 7%\n",
      "\n",
      "==============================\n",
      "TABLE INDEX: 6\n",
      "HEADING: Balance Sheet\n",
      "SHAPE: (10, 14)\n",
      "            Unnamed: 0  Mar 2014  Mar 2015  Mar 2016  Mar 2017  Mar 2018  \\\n",
      "0       Equity Capital      3232      3236      3240      3251      6335   \n",
      "1             Reserves    193859    212940    250758    285062    308312   \n",
      "2         Borrowings +     89968     97620    107104    107446    116881   \n",
      "3  Other Liabilities +     80524     83989    120572    150987    185997   \n",
      "4    Total Liabilities    367583    397785    481674    546746    617525   \n",
      "\n",
      "   Mar 2019  Mar 2020  Mar 2021  Mar 2022  Mar 2023  Mar 2024  Mar 2025  \\\n",
      "0      6339      6339      6445      6765      6766      6766     13532   \n",
      "1    398983    384876    468038    464762    472312    508330    529555   \n",
      "2    161720    298599    224683    197439    218706    214575    201505   \n",
      "3    208703    281885    174507    209708    224876    229972    277809   \n",
      "4    775745    971699    873673    878674    922660    959643   1022401   \n",
      "\n",
      "   Sep 2025  \n",
      "0     13532  \n",
      "1    544964  \n",
      "2    207388  \n",
      "3    302764  \n",
      "4   1068648  \n",
      "\n",
      "==============================\n",
      "TABLE INDEX: 7\n",
      "HEADING: Cash Flows\n",
      "SHAPE: (4, 13)\n",
      "                       Unnamed: 0  Mar 2014  Mar 2015  Mar 2016  Mar 2017  \\\n",
      "0  Cash from Operating Activity +     42160     35285     43447     51450   \n",
      "1  Cash from Investing Activity +    -64013    -55998    -41223    -54949   \n",
      "2  Cash from Financing Activity +      5530      -940     -6903     -1639   \n",
      "3                   Net Cash Flow    -16323    -21653     -4679     -5138   \n",
      "\n",
      "   Mar 2018  Mar 2019  Mar 2020  Mar 2021  Mar 2022  Mar 2023  Mar 2024  \\\n",
      "0     62000     29191     77533      -512     67491     55340     73998   \n",
      "1    -59109    -53949   -143583     74257    -45315     -8678    -38292   \n",
      "2     -1914     25795     70767    -76657     -6035     -7369    -27465   \n",
      "3       977      1037      4717     -2912     16141     39293      8241   \n",
      "\n",
      "   Mar 2025  \n",
      "0     79392  \n",
      "1    -28106  \n",
      "2    -38063  \n",
      "3     13223  \n",
      "\n",
      "==============================\n",
      "TABLE INDEX: 8\n",
      "HEADING: Ratios\n",
      "SHAPE: (6, 13)\n",
      "              Unnamed: 0 Mar 2014 Mar 2015 Mar 2016 Mar 2017 Mar 2018  \\\n",
      "0            Debtor Days       10        5        6        8       13   \n",
      "1         Inventory Days       47       50       63       75       71   \n",
      "2           Days Payable       64       75      123      151      160   \n",
      "3  Cash Conversion Cycle       -6      -19      -54      -67      -76   \n",
      "4   Working Capital Days      -28      -41     -128     -152     -155   \n",
      "\n",
      "  Mar 2019 Mar 2020 Mar 2021 Mar 2022 Mar 2023 Mar 2024 Mar 2025  \n",
      "0       12        8        6       12       16       10       11  \n",
      "1       60       58       78       52       77       79       84  \n",
      "2      119      106      180      151      108      121      115  \n",
      "3      -48      -40      -96      -87      -15      -32      -20  \n",
      "4     -111     -263     -136      -68      -77      -79      -91  \n",
      "\n",
      "==============================\n",
      "TABLE INDEX: 9\n",
      "HEADING: Shareholding Pattern\n",
      "SHAPE: (6, 13)\n",
      "     Unnamed: 0 Dec 2022 Mar 2023 Jun 2023 Sep 2023 Dec 2023 Mar 2024  \\\n",
      "0   Promoters +   50.49%   50.41%   50.39%   50.27%   50.30%   50.31%   \n",
      "1        FIIs +   23.48%   22.49%   22.55%   22.60%   22.13%   22.06%   \n",
      "2        DIIs +   15.26%   16.06%   16.13%   15.99%   16.59%   16.98%   \n",
      "3  Government +    0.16%    0.16%    0.17%    0.17%    0.18%    0.19%   \n",
      "4      Public +   10.59%   10.89%   10.76%   10.98%   10.80%   10.46%   \n",
      "\n",
      "  Jun 2024 Sep 2024 Dec 2024 Mar 2025 Jun 2025 Sep 2025  \n",
      "0   50.33%   50.24%   50.13%   50.10%   50.07%   50.01%  \n",
      "1   21.75%   21.30%   19.16%   19.07%   19.21%   18.65%  \n",
      "2   17.30%   17.61%   19.02%   19.36%   19.72%   20.25%  \n",
      "3    0.19%    0.19%    0.18%    0.17%    0.17%    0.17%  \n",
      "4   10.43%   10.67%   11.52%   11.29%   10.84%   10.92%  \n",
      "\n",
      "==============================\n",
      "TABLE INDEX: 10\n",
      "HEADING: Shareholding Pattern\n",
      "SHAPE: (6, 11)\n",
      "     Unnamed: 0 Mar 2017 Mar 2018 Mar 2019 Mar 2020 Mar 2021 Mar 2022  \\\n",
      "0   Promoters +   46.32%   47.45%   47.27%   50.07%   50.58%   50.66%   \n",
      "1        FIIs +   22.58%   24.46%   24.39%   24.08%   25.66%   24.23%   \n",
      "2        DIIs +   11.85%   11.23%   11.86%   13.78%   12.62%   14.23%   \n",
      "3  Government +    0.14%    0.15%    0.18%    0.20%    0.20%    0.17%   \n",
      "4      Public +   19.12%   16.72%   16.29%   11.87%   10.94%   10.71%   \n",
      "\n",
      "  Mar 2023 Mar 2024 Mar 2025 Sep 2025  \n",
      "0   50.41%   50.31%   50.10%   50.01%  \n",
      "1   22.49%   22.06%   19.07%   18.65%  \n",
      "2   16.06%   16.98%   19.36%   20.25%  \n",
      "3    0.16%    0.19%    0.17%    0.17%  \n",
      "4   10.89%   10.46%   11.29%   10.92%  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jallu\\AppData\\Local\\Temp\\ipykernel_90600\\1036851876.py:5: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(str(soup))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 1. Get all tables\n",
    "tables = pd.read_html(str(soup))\n",
    "\n",
    "# 2. Find all table elements in HTML (same order as read_html)\n",
    "html_tables = soup.find_all(\"table\")\n",
    "\n",
    "print(f\"Total tables found: {len(html_tables)}\")\n",
    "\n",
    "# 3. For each table, find nearest preceding heading\n",
    "for idx, table in enumerate(html_tables):\n",
    "    heading = None\n",
    "\n",
    "    # Look backwards for the nearest h2 or h3\n",
    "    for prev in table.find_all_previous([\"h2\", \"h3\"], limit=1):\n",
    "        heading = prev.get_text(strip=True)\n",
    "        break\n",
    "\n",
    "    print(\"\\n==============================\")\n",
    "    print(f\"TABLE INDEX: {idx}\")\n",
    "    print(\"HEADING:\", heading if heading else \"No heading found\")\n",
    "    print(\"SHAPE:\", tables[idx].shape)\n",
    "    print(tables[idx].head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9464652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Quarterly Results\n",
      "1: Profit & Loss\n",
      "2: Balance Sheet\n",
      "3: Cash Flows\n",
      "4: Ratios\n",
      "5: Shareholding Pattern\n"
     ]
    }
   ],
   "source": [
    "# Collect headings with possible repeats\n",
    "raw_headings = []\n",
    "\n",
    "html_tables = soup.find_all(\"table\")\n",
    "\n",
    "for table in html_tables:\n",
    "    heading = None\n",
    "    for prev in table.find_all_previous([\"h2\", \"h3\"], limit=1):\n",
    "        heading = prev.get_text(strip=True)\n",
    "        break\n",
    "    raw_headings.append(heading if heading else \"No heading\")\n",
    "\n",
    "# Deduplicate while preserving order\n",
    "unique_headings = []\n",
    "for h in raw_headings:\n",
    "    if h not in unique_headings:\n",
    "        unique_headings.append(h)\n",
    "\n",
    "# Print only unique names\n",
    "for i, h in enumerate(unique_headings):\n",
    "    print(f\"{i}: {h}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9349db37",
   "metadata": {},
   "outputs": [
    {
     "ename": "ReadTimeout",
     "evalue": "HTTPSConnectionPool(host='www.nseindia.com', port=443): Read timed out. (read timeout=20)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTimeoutError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\urllib3\\connectionpool.py:468\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[39m\n\u001b[32m    464\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    465\u001b[39m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[32m    466\u001b[39m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[32m    467\u001b[39m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m468\u001b[39m             \u001b[43msix\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:3\u001b[39m, in \u001b[36mraise_from\u001b[39m\u001b[34m(value, from_value)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\urllib3\\connectionpool.py:463\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[39m\n\u001b[32m    462\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m463\u001b[39m     httplib_response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    464\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    465\u001b[39m     \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[32m    466\u001b[39m     \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[32m    467\u001b[39m     \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python313\\Lib\\http\\client.py:1430\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1429\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1430\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1431\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python313\\Lib\\http\\client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python313\\Lib\\http\\client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python313\\Lib\\socket.py:719\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python313\\Lib\\ssl.py:1304\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1301\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1302\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1303\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1305\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python313\\Lib\\ssl.py:1138\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1138\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1139\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mTimeoutError\u001b[39m: The read operation timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mReadTimeoutError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\requests\\adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\urllib3\\connectionpool.py:802\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[39m\n\u001b[32m    800\u001b[39m     e = ProtocolError(\u001b[33m\"\u001b[39m\u001b[33mConnection aborted.\u001b[39m\u001b[33m\"\u001b[39m, e)\n\u001b[32m--> \u001b[39m\u001b[32m802\u001b[39m retries = \u001b[43mretries\u001b[49m\u001b[43m.\u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    803\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m=\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m=\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    804\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    805\u001b[39m retries.sleep()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\urllib3\\util\\retry.py:552\u001b[39m, in \u001b[36mRetry.increment\u001b[39m\u001b[34m(self, method, url, response, error, _pool, _stacktrace)\u001b[39m\n\u001b[32m    551\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_method_retryable(method):\n\u001b[32m--> \u001b[39m\u001b[32m552\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43msix\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\urllib3\\packages\\six.py:770\u001b[39m, in \u001b[36mreraise\u001b[39m\u001b[34m(tp, value, tb)\u001b[39m\n\u001b[32m    769\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m value.with_traceback(tb)\n\u001b[32m--> \u001b[39m\u001b[32m770\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[32m    771\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\urllib3\\connectionpool.py:716\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[39m\n\u001b[32m    715\u001b[39m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m716\u001b[39m httplib_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    717\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    718\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    719\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    721\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    722\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    723\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    724\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    726\u001b[39m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[32m    727\u001b[39m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[32m    728\u001b[39m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[32m    729\u001b[39m \u001b[38;5;66;03m# mess.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\urllib3\\connectionpool.py:470\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[39m\n\u001b[32m    469\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m470\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_timeout\u001b[49m\u001b[43m(\u001b[49m\u001b[43merr\u001b[49m\u001b[43m=\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mread_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    471\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\urllib3\\connectionpool.py:358\u001b[39m, in \u001b[36mHTTPConnectionPool._raise_timeout\u001b[39m\u001b[34m(self, err, url, timeout_value)\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(err, SocketTimeout):\n\u001b[32m--> \u001b[39m\u001b[32m358\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeoutError(\n\u001b[32m    359\u001b[39m         \u001b[38;5;28mself\u001b[39m, url, \u001b[33m\"\u001b[39m\u001b[33mRead timed out. (read timeout=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m % timeout_value\n\u001b[32m    360\u001b[39m     )\n\u001b[32m    362\u001b[39m \u001b[38;5;66;03m# See the above comment about EAGAIN in Python 3. In Python 2 we have\u001b[39;00m\n\u001b[32m    363\u001b[39m \u001b[38;5;66;03m# to specifically catch it and throw the timeout error\u001b[39;00m\n",
      "\u001b[31mReadTimeoutError\u001b[39m: HTTPSConnectionPool(host='www.nseindia.com', port=443): Read timed out. (read timeout=20)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mReadTimeout\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 68\u001b[39m\n\u001b[32m     58\u001b[39m             w.writerow({\n\u001b[32m     59\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33msymbol\u001b[39m\u001b[33m\"\u001b[39m: symbol,\n\u001b[32m     60\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mcompany\u001b[39m\u001b[33m\"\u001b[39m: company,\n\u001b[32m   (...)\u001b[39m\u001b[32m     64\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mpdfLink\u001b[39m\u001b[33m\"\u001b[39m: BASE + attach_url \u001b[38;5;28;01mif\u001b[39;00m attach_url \u001b[38;5;129;01mand\u001b[39;00m attach_url.startswith(\u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (attach_url \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     65\u001b[39m             })\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m     \u001b[43mfetch_nse_announcements\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mfetch_nse_announcements\u001b[39m\u001b[34m(max_records, out_csv)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfetch_nse_announcements\u001b[39m(max_records=\u001b[32m500\u001b[39m, out_csv=\u001b[33m\"\u001b[39m\u001b[33mnse_announcements.csv\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     27\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[33;03m    Fetch latest corporate announcements and save to CSV.\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[33;03m    Handles both list and dict-with-data responses.\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     data = \u001b[43mnse_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/api/corporate-announcements\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mindex\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mequities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrom_date\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mto_date\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompany\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mindustry\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m     \u001b[38;5;66;03m# Normalise: API may return list OR {\"data\": [...]}\u001b[39;00m\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mlist\u001b[39m):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mnse_get\u001b[39m\u001b[34m(path, params, delay)\u001b[39m\n\u001b[32m     20\u001b[39m time.sleep(delay)\n\u001b[32m     21\u001b[39m url = BASE + path\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m r = \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m r.raise_for_status()\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m r.json()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\requests\\sessions.py:602\u001b[39m, in \u001b[36mSession.get\u001b[39m\u001b[34m(self, url, **kwargs)\u001b[39m\n\u001b[32m    594\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[32m    595\u001b[39m \n\u001b[32m    596\u001b[39m \u001b[33;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m    597\u001b[39m \u001b[33;03m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[32m    598\u001b[39m \u001b[33;03m:rtype: requests.Response\u001b[39;00m\n\u001b[32m    599\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    601\u001b[39m kwargs.setdefault(\u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m602\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGET\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\requests\\adapters.py:713\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    711\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request=request)\n\u001b[32m    712\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, ReadTimeoutError):\n\u001b[32m--> \u001b[39m\u001b[32m713\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeout(e, request=request)\n\u001b[32m    714\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, _InvalidHeader):\n\u001b[32m    715\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidHeader(e, request=request)\n",
      "\u001b[31mReadTimeout\u001b[39m: HTTPSConnectionPool(host='www.nseindia.com', port=443): Read timed out. (read timeout=20)"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import time\n",
    "import csv\n",
    "import requests\n",
    "\n",
    "BASE = \"https://www.nseindia.com\"\n",
    "HEADERS = {\n",
    "    \"User-Agent\": (\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/120.0 Safari/537.36\"\n",
    "    ),\n",
    "    \"Accept\": \"application/json, text/plain, */*\",\n",
    "    \"Referer\": \"https://www.nseindia.com/companies-listing/corporate-filings-announcements\",\n",
    "}\n",
    "\n",
    "session = requests.Session()\n",
    "session.headers.update(HEADERS)\n",
    "\n",
    "def nse_get(path, params=None, delay=1.5):\n",
    "    time.sleep(delay)\n",
    "    url = BASE + path\n",
    "    r = session.get(url, params=params, timeout=20)\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "def fetch_nse_announcements(max_records=500, out_csv=\"nse_announcements.csv\"):\n",
    "    \"\"\"\n",
    "    Fetch latest corporate announcements and save to CSV.\n",
    "    Handles both list and dict-with-data responses.\n",
    "    \"\"\"\n",
    "    data = nse_get(\n",
    "        \"/api/corporate-announcements\",\n",
    "        params={\"index\": \"equities\", \"from_date\": \"\", \"to_date\": \"\", \"company\": \"\", \"industry\": \"\"},\n",
    "    )\n",
    "\n",
    "    # Normalise: API may return list OR {\"data\": [...]}\n",
    "    if isinstance(data, list):\n",
    "        rows = data\n",
    "    elif isinstance(data, dict):\n",
    "        rows = data.get(\"data\", [])\n",
    "    else:\n",
    "        rows = []\n",
    "\n",
    "    rows = rows[:max_records]\n",
    "\n",
    "    fields = [\"symbol\", \"company\", \"headline\", \"ann_date\", \"attachment\", \"pdfLink\"]\n",
    "    with open(out_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=fields)\n",
    "        w.writeheader()\n",
    "        for r in rows:\n",
    "            symbol = r.get(\"symbol\") or r.get(\"securitySymbol\")\n",
    "            company = r.get(\"companyName\") or r.get(\"company\")\n",
    "            headline = r.get(\"subject\") or r.get(\"headline\")\n",
    "            ann_date = r.get(\"announcementDate\") or r.get(\"announcedDate\")\n",
    "            attachment_name = r.get(\"attachmentName\") or r.get(\"fileName\")\n",
    "            attach_url = r.get(\"attachmentUrl\") or r.get(\"fileUrl\")\n",
    "\n",
    "            w.writerow({\n",
    "                \"symbol\": symbol,\n",
    "                \"company\": company,\n",
    "                \"headline\": headline,\n",
    "                \"ann_date\": ann_date,\n",
    "                \"attachment\": attachment_name,\n",
    "                \"pdfLink\": BASE + attach_url if attach_url and attach_url.startswith(\"/\") else (attach_url or \"\"),\n",
    "            })\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    fetch_nse_announcements()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
